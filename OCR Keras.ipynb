{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.python.keras.layers import Input, Dense, Activation\n",
    "from tensorflow.python.keras.layers import Reshape, Lambda\n",
    "from tensorflow.python.keras.layers import GRU\n",
    "from tensorflow.python.keras.layers import add, concatenate\n",
    "from tensorflow.python.keras.models import Model, load_model\n",
    "from tensorflow.python.keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### misc imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import json\n",
    "import random\n",
    "import itertools\n",
    "import re\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.0'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max plate length in \"train\": 8\n",
      "Max plate length in \"train\": 8\n",
      "Letters in train and val do match\n",
      "Letters: 0 1 2 3 4 5 6 7 8 9 A B C E H K M O P T X Y\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def get_counter(dirpath):\n",
    "    dirname = os.path.basename(dirpath)\n",
    "    ann_dirpath = join(dirpath, 'ann')\n",
    "    letters = ''\n",
    "    lens = []\n",
    "    for filename in os.listdir(ann_dirpath):\n",
    "        json_filepath = join(ann_dirpath, filename)\n",
    "        description = json.load(open(json_filepath, 'r'))['description']\n",
    "        lens.append(len(description))\n",
    "        letters += description\n",
    "    print('Max plate length in \"%s\":' % dirname, max(Counter(lens).keys()))\n",
    "    return Counter(letters)\n",
    "c_val = get_counter('/home/martin/workspace/datasets/ocr-2213/val/anpr_ocr/train')\n",
    "c_train = get_counter('/home/martin/workspace/datasets/ocr-2213/train/anpr_ocr/train')\n",
    "letters_train = set(c_train.keys())\n",
    "letters_val = set(c_val.keys())\n",
    "if letters_train == letters_val:\n",
    "    print('Letters in train and val do match')\n",
    "else:\n",
    "    raise Exception()\n",
    "# print(len(letters_train), len(letters_val), len(letters_val | letters_train))\n",
    "letters = sorted(list(letters_train))\n",
    "print('Letters:', ' '.join(letters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# input generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labels_to_text(labels):\n",
    "    return ''.join(list(map(lambda x: letters[int(x)], labels)))\n",
    "\n",
    "def text_to_labels(text):\n",
    "    return list(map(lambda x: letters.index(x), text))\n",
    "\n",
    "def is_valid_str(s):\n",
    "    for ch in s:\n",
    "        if not ch in letters:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "class TextImageGenerator:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 dirpath, \n",
    "                 img_w, img_h, \n",
    "                 batch_size, \n",
    "                 downsample_factor,\n",
    "                 max_text_len=8):\n",
    "        \n",
    "        self.img_h = img_h\n",
    "        self.img_w = img_w\n",
    "        self.batch_size = batch_size\n",
    "        self.max_text_len = max_text_len\n",
    "        self.downsample_factor = downsample_factor\n",
    "        \n",
    "        img_dirpath = join(dirpath, 'img')\n",
    "        ann_dirpath = join(dirpath, 'ann')\n",
    "        self.samples = []\n",
    "        for filename in os.listdir(img_dirpath):\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            if ext == '.png':\n",
    "                img_filepath = join(img_dirpath, filename)\n",
    "                json_filepath = join(ann_dirpath, name + '.json')\n",
    "                description = json.load(open(json_filepath, 'r'))['description']\n",
    "                if is_valid_str(description):\n",
    "                    self.samples.append([img_filepath, description])\n",
    "        \n",
    "        self.n = len(self.samples)\n",
    "        self.indexes = list(range(self.n))\n",
    "        self.cur_index = 0\n",
    "        \n",
    "    def build_data(self):\n",
    "        self.imgs = np.zeros((self.n, self.img_h, self.img_w))\n",
    "        self.texts = []\n",
    "        for i, (img_filepath, text) in enumerate(self.samples):\n",
    "            img = cv2.imread(img_filepath)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img = cv2.resize(img, (self.img_w, self.img_h))\n",
    "            img = img.astype(np.float32)\n",
    "            img /= 255\n",
    "            # width and height are backwards from typical Keras convention\n",
    "            # because width is the time dimension when it gets fed into the RNN\n",
    "            self.imgs[i, :, :] = img\n",
    "            self.texts.append(text)\n",
    "        \n",
    "    def get_output_size(self):\n",
    "        return len(letters) + 1\n",
    "    \n",
    "    def next_sample(self):\n",
    "        self.cur_index += 1\n",
    "        if self.cur_index >= self.n:\n",
    "            self.cur_index = 0\n",
    "            random.shuffle(self.indexes)\n",
    "        return self.imgs[self.indexes[self.cur_index]], self.texts[self.indexes[self.cur_index]]\n",
    "    \n",
    "    def next_batch(self):\n",
    "        while True:\n",
    "            # width and height are backwards from typical Keras convention\n",
    "            # because width is the time dimension when it gets fed into the RNN\n",
    "            if tf.keras.backend.image_data_format() == 'channels_first':\n",
    "                X_data = np.ones([self.batch_size, 1, self.img_w, self.img_h])\n",
    "            else:\n",
    "                X_data = np.ones([self.batch_size, self.img_w, self.img_h, 1])\n",
    "            Y_data = np.ones([self.batch_size, self.max_text_len])\n",
    "            input_length = np.ones((self.batch_size, 1)) * (self.img_w // self.downsample_factor - 2)\n",
    "            label_length = np.zeros((self.batch_size, 1))\n",
    "            source_str = []\n",
    "                                   \n",
    "            for i in range(self.batch_size):\n",
    "                img, text = self.next_sample()\n",
    "                img = img.T\n",
    "                if tf.keras.backend.image_data_format() == 'channels_first':\n",
    "                    img = np.expand_dims(img, 0)\n",
    "                else:\n",
    "                    img = np.expand_dims(img, -1)\n",
    "                X_data[i] = img\n",
    "                Y_data[i] = text_to_labels(text)\n",
    "                source_str.append(text)\n",
    "                label_length[i] = len(text)\n",
    "                \n",
    "            inputs = {\n",
    "                'the_input': X_data,\n",
    "                'the_labels': Y_data,\n",
    "                'input_length': input_length,\n",
    "                'label_length': label_length,\n",
    "                #'source_str': source_str\n",
    "            }\n",
    "            outputs = {'ctc': np.zeros([self.batch_size])}\n",
    "            yield (inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiger = TextImageGenerator('/home/martin/workspace/datasets/ocr-2213/val/anpr_ocr/train', 128, 64, 8, 4)\n",
    "tiger.build_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 4\n",
      "Batch inp type: <class 'dict'>\n",
      "Text generator output (data which will be fed into the neutral network):\n",
      "1) the_input (image)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADKCAYAAAC11LviAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxAs9CIJgRIgXehAEwYgQL/QgCIIR4f8D/7rlVaVpyoIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8f0bf017b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2) the_labels (plate number): H223PH49 is encoded as [14, 2, 2, 3, 18, 14, 4, 9]\n",
      "3) input_length (width of image that is fed to the loss function): 30 == 128 / 4 - 2\n",
      "4) label_length (length of plate number): 8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inp, out = next(tiger.next_batch())\n",
    "print(f\"Batch size: {len(inp)}\")\n",
    "print(f\"Batch inp type: {type(inp)}\")\n",
    "print('Text generator output (data which will be fed into the neutral network):')\n",
    "print('1) the_input (image)')\n",
    "if tf.keras.backend.image_data_format() == 'channels_first':\n",
    "    img = inp['the_input'][0, 0, :, :]\n",
    "else:\n",
    "    img = inp['the_input'][0, :, :, 0]\n",
    "\n",
    "plt.imshow(img.T, cmap='gray')\n",
    "plt.show()\n",
    "print('2) the_labels (plate number): %s is encoded as %s' % \n",
    "      (labels_to_text(inp['the_labels'][0]), list(map(int, inp['the_labels'][0]))))\n",
    "print('3) input_length (width of image that is fed to the loss function): %d == %d / 4 - 2' % \n",
    "      (inp['input_length'][0], tiger.img_w))\n",
    "print('4) label_length (length of plate number): %d' % inp['label_length'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 128, 64, 1)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (batch_size, img_w, img_h, channels)\n",
    "inp['the_input'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('H223PH49', [14, 2, 2, 3, 18, 14, 4, 9])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp['the_labels'][0]\n",
    "labels_to_text(inp['the_labels'][0]), list(map(int, inp['the_labels'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ctc': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['ctc'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and train functions, network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Model, load_model\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return tf.keras.backend.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "\n",
    "def train(img_w, load=False):\n",
    "    # Input Parameters\n",
    "    img_h = 64\n",
    "\n",
    "    # Network parameters\n",
    "    conv_filters = 16\n",
    "    kernel_size = (3, 3)\n",
    "    pool_size = 2\n",
    "    time_dense_size = 32\n",
    "    rnn_size = 512\n",
    "\n",
    "    if tf.keras.backend.image_data_format() == 'channels_first':\n",
    "        input_shape = (1, img_w, img_h)\n",
    "    else:\n",
    "        input_shape = (img_w, img_h, 1)\n",
    "        \n",
    "    batch_size = 32\n",
    "    downsample_factor = pool_size ** 2\n",
    "    tiger_train = TextImageGenerator('/home/martin/workspace/datasets/ocr-2213/train/anpr_ocr/train/', img_w, img_h, batch_size, downsample_factor)\n",
    "    tiger_train.build_data()\n",
    "    tiger_val = TextImageGenerator('/home/martin/workspace/datasets/ocr-2213/val/anpr_ocr/train', img_w, img_h, batch_size, downsample_factor)\n",
    "    tiger_val.build_data()\n",
    "\n",
    "    act = 'relu'\n",
    "    input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "    inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "                   activation=act, kernel_initializer='he_normal',\n",
    "                   name='conv1')(input_data)\n",
    "    inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max1')(inner)\n",
    "    inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "                   activation=act, kernel_initializer='he_normal',\n",
    "                   name='conv2')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')(inner)\n",
    "\n",
    "    conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)\n",
    "    inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n",
    "\n",
    "    # cuts down input size going into RNN:\n",
    "    inner = Dense(time_dense_size, activation=act, name='dense1')(inner)\n",
    "\n",
    "    # Two layers of bidirecitonal GRUs\n",
    "    # GRU seems to work as well, if not better than LSTM:\n",
    "    gru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')(inner)\n",
    "    gru_1b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru1_b')(inner)\n",
    "    gru1_merged = add([gru_1, gru_1b])\n",
    "    gru_2 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
    "    gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n",
    "\n",
    "    # transforms RNN output to character activations:\n",
    "    inner = Dense(tiger_train.get_output_size(), kernel_initializer='he_normal',\n",
    "                  name='dense2')(concatenate([gru_2, gru_2b]))\n",
    "    y_pred = Activation('softmax', name='softmax')(inner)\n",
    "    Model(inputs=input_data, outputs=y_pred).summary()\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[tiger_train.max_text_len], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "    # \n",
    "    # so CTC loss is implemented in a lambda layer\n",
    "    loss_out = Lambda(ctc_lambda_func, (1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    # clipnorm seems to speeds up convergence\n",
    "    sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "\n",
    "    if load:\n",
    "        model = load_model('./tmp_model.h5', compile=False)\n",
    "    else:\n",
    "        model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "    # the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n",
    "    \n",
    "    if not load:\n",
    "        # captures output of softmax so we can decode the output during visualization\n",
    "        test_func = tf.keras.backend.function([input_data], [y_pred])\n",
    "\n",
    "        model.fit_generator(generator=tiger_train.next_batch(), \n",
    "                            steps_per_epoch=tiger_train.n,\n",
    "                            epochs=1, \n",
    "                            validation_data=tiger_val.next_batch(), \n",
    "                            validation_steps=tiger_val.n)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model description and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "the_input (InputLayer)           (None, 128, 64, 1)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                   (None, 128, 64, 16)   160         the_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max1 (MaxPooling2D)              (None, 64, 32, 16)    0           conv1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                   (None, 64, 32, 16)    2320        max1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "max2 (MaxPooling2D)              (None, 32, 16, 16)    0           conv2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "reshape (Reshape)                (None, 32, 256)       0           max2[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dense1 (Dense)                   (None, 32, 32)        8224        reshape[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "gru1 (GRU)                       (None, None, 512)     837120      dense1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "gru1_b (GRU)                     (None, None, 512)     837120      dense1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "add_9 (Add)                      (None, None, 512)     0           gru1[0][0]                       \n",
      "                                                                   gru1_b[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "gru2 (GRU)                       (None, None, 512)     1574400     add_9[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "gru2_b (GRU)                     (None, None, 512)     1574400     add_9[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)      (None, None, 1024)    0           gru2[0][0]                       \n",
      "                                                                   gru2_b[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense2 (Dense)                   (None, None, 23)      23575       concatenate_9[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "softmax (Activation)             (None, None, 23)      0           dense2[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 4,857,319\n",
      "Trainable params: 4,857,319\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/1\n",
      " 2846/10307 [=======>......................] - ETA: 4508s - loss: 1.0044"
     ]
    }
   ],
   "source": [
    "model = train(128, load=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensorflow' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-69a5ee7bb0a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tensorflow' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "tensorflow.python.keras.backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow.python.keras.backend' from '/home/martin/anaconda3/envs/dlf/lib/python3.6/site-packages/tensorflow/python/keras/backend/__init__.py'>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensorflow' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-69a5ee7bb0a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tensorflow' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "tensorflow.python.keras.backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dlf]",
   "language": "python",
   "name": "conda-env-dlf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
